{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f0385-4b2c-4a16-a312-561fa562a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "import tkinter.filedialog as fd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "# from multiprocessing import Pool\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "# import ray \n",
    "# ray.init(num_gpus=0,ignore_reinit_error=True)\n",
    "# import modin.pandas as mpd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30843aa5-7c92-4ede-afe0-720c656a7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enabling notebook extension jupyter-js-widgets/extension...\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "# Hide these warnings\n",
    "warnings.filterwarnings(action='once', message='.*Mean of empty slice.*')\n",
    "\n",
    "# Some plotting presets\n",
    "plt.rc(\"figure\", dpi=70)\n",
    "plt.rc(\"savefig\", dpi=30, facecolor=\"white\", bbox=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362b5ec-25dd-41d1-81b1-d98b84d073e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print python version\n",
    "python_version = sys.version\n",
    "print(python_version)\n",
    "\n",
    "## Choose analysis files\n",
    "initial_dir = \"C:\\\\Users\"\n",
    "print(\"Please select the files to analyze:\")\n",
    "\n",
    "time.sleep(0.25)\n",
    "root = tk.Tk()\n",
    "root.filenames = fd.askopenfilenames(initialdir=initial_dir,\n",
    "                                     title=\"Please select the files to analyze\",\n",
    "                                     filetypes=((\"csv files\", \"*.csv\"), (\"all files\", \"*.*\")))\n",
    "input_files = [os.path.basename(f) for f in root.filenames]\n",
    "input_dir = os.path.dirname(root.filenames[0])\n",
    "root.destroy()\n",
    "\n",
    "print(\"Please choose the output folder:\")\n",
    "time.sleep(0.25)\n",
    "\n",
    "root = tk.Tk()\n",
    "root.filenames = fd.askdirectory(initialdir=input_dir,\n",
    "                                 title=\"Please select the output folder\")\n",
    "output_dir = root.filenames\n",
    "root.destroy()\n",
    "\n",
    "os.chdir(input_dir)\n",
    "print('Working directory is:', input_dir, '\\n')\n",
    "print('Output folder is:', output_dir,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e852b03d-ff70-4dda-946d-3be70fe80817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary containing the original and excel-friendly names of all the per-well metrics desired\n",
    "info_per_day = {\n",
    "    'Original File Time':'Original File Time',\n",
    "    'Experiment Start Time':'Experiment Start Time',\n",
    "    'Well':'Well', # Encabezado de datos por pocillo\n",
    "    'Active':'Active',\n",
    "    'Well Coloring':'Well Coloring',\n",
    "    'Control':'Control',\n",
    "    'Treatment':'Treatment',\n",
    "    'Concentration':'Concentration',\n",
    "    'Additional Information':'Additional Information',\n",
    "    'Analysis Start (s):':'Analysis Start (s):',\n",
    "    'Analysis Duration (s):':'Analysis Duration (s)',\n",
    "    'Treatment Averages':'Treatment Averages', # Encabezado de datos por tratamiento\n",
    "    'Measurement':'Electrode'# Encabezado de datos por electrodo\n",
    "}\n",
    "# Check if all names are <=31 chars long\n",
    "for i in info_per_day.values():\n",
    "    if len(i) > 31:\n",
    "        print(f'\\n{i} in \"info_per_day\" is {len(i)} characters long, {len(i) - 31} characters over the excel worksheet name limit')\n",
    "print(f'\\n{len(info_per_day)} well info parameters will be extracted from the advanced metrics.csv files')\n",
    "\n",
    "metrics_per_treatment = {\n",
    "    'Total Wells':'Total Wells',\n",
    "    'Number of Spikes - Avg':'Number of Spikes - Avg',\n",
    "    'Number of Spikes - Std':'Number of Spikes - Std',\n",
    "    'Mean Firing Rate (Hz) - Avg':'Mean Firing Rate (Hz) - Avg',\n",
    "    'Mean Firing Rate (Hz) - Std':'Mean Firing Rate (Hz) - Std',\n",
    "    'Number of Active Electrodes - Avg':'NumberActiveElect-Avg',\n",
    "    'Number of Active Electrodes - Std':'NumberActiveElect-Std',\n",
    "    'Weighted Mean Firing Rate (Hz) - Avg':'WeightedSpikeRate(Hz)-Avg',\n",
    "    'Weighted Mean Firing Rate (Hz) - Std':'WeightedSpikeRate(Hz)-Std',\n",
    "    'Number of Bursts - Avg':'Number of Bursts - Avg',\n",
    "    'Number of Bursts - Std':'Number of Bursts - Std',\n",
    "    'Burst Duration - Avg (s)':'Burst Duration - Avg (s)',\n",
    "    'Burst Duration - Std (s)':'Burst Duration - Std (s)',\n",
    "    'Inter-Burst Interval - Avg (s)':'Inter-Burst Interval - Avg (s)',\n",
    "    'Inter-Burst Interval - Std (s)':'Inter-Burst Interval - Std (s)',\n",
    "    'Burst Frequency - Avg (Hz)':'Burst Frequency - Avg (Hz)',\n",
    "    'Burst Frequency - Std (Hz)':'Burst Frequency - Std (Hz)',\n",
    "    'Normalized Duration IQR - Avg':'Normalized Duration IQR - Avg',\n",
    "    'Normalized Duration IQR - Std':'Normalized Duration IQR - Std',\n",
    "    'IBI Coefficient of Variation - Avg':'IBICoeffVar-Avg',\n",
    "    'IBI Coefficient of Variation - Std':'IBICoeffVar-Std',\n",
    "    'Burst Percentage - Avg':'Burst Percentage - Avg',\n",
    "    'Burst Percentage - Std':'Burst Percentage - Std',\n",
    "    'Number of Network Bursts - Avg':'Number of Network Bursts - Avg',\n",
    "    'Number of Network Bursts - Std':'Number of Network Bursts - Std',\n",
    "    'Network Burst Frequency - Avg (Hz)':'NetBurst Freq-Avg(Hz)',\n",
    "    'Network Burst Frequency - Std (Hz)':'NetBurstFreq-Std(Hz)',\n",
    "    'Network Burst Duration - Avg (sec)':'NetBurstDuration-Avg(sec)',\n",
    "    'Network Burst Duration - Std (sec)':'NetBurstDuration-Std(sec)',\n",
    "    'Number of Elecs Participating in Burst - Avg':'ElecsParticipatingInBurst-Avg',\n",
    "    'Number of Elecs Participating in Burst - Std':'ElecsParticipatingInBurst-Std',\n",
    "    'Network Burst Percentage - Avg':'Network Burst Percentage - Avg',\n",
    "    'Network Burst Percentage - Std':'Network Burst Percentage - Std',\n",
    "    'Network IBI Coefficient of Variation - Avg':'NetIBICoeffVariation-Avg',\n",
    "    'Network IBI Coefficient of Variation - Std':'NetIBICoeffVariation-Std',\n",
    "    'Network Normalized Duration IQR - Avg':'NetNormalizedDurationIQR-Avg',\n",
    "    'Network Normalized Duration IQR - Std':'NetNormalizedDurationIQR-Std',\n",
    "    'Area Under Normalized Cross-Correlation - Avg':'AreaUnderNormCross-Corr-Avg',\n",
    "    'Area Under Normalized Cross-Correlation - Std':'AreaUnderNormCross-Corr-Std',\n",
    "    'Area Under Cross-Correlation - Avg':'AreaUnderCross-Correlation-Avg',\n",
    "    'Area Under Cross-Correlation - Std':'AreaUnderCross-Correlation-Std'\n",
    "}\n",
    "\n",
    "# Check if all names are <=31 chars long\n",
    "for i in metrics_per_treatment.values():\n",
    "    if len(i) > 31:\n",
    "        print(f'\\n{i} in \"metrics_per_treatment\" is {len(i)} characters long, {len(i) - 31} characters over the excel worksheet name limit')\n",
    "print(f'\\n{len(metrics_per_treatment)} treatment metrics will be extracted from the advanced metrics.csv files')\n",
    "\n",
    "metrics_per_well = {\n",
    "    'Number of Spikes':'Number_of_Spikes',\n",
    "    'Mean Firing Rate (Hz)':'Mean_Firing_Rate_Hz_well',\n",
    "    'Number of Active Electrodes':'Number_of_Active_Electrodes',\n",
    "    'Weighted Mean Firing Rate (Hz)':'Weighted_Mean_Firing_Rate_Hz',\n",
    "    'ISI Coefficient of Variation - Avg':'ISI_Coeff_of_Variation_Avg',\n",
    "    'Number of Bursts':'Number_of_Bursts',\n",
    "    'Number of Bursting Electrodes':'Number_of_Bursting_Electrodes',\n",
    "    'Burst Duration - Avg (s)':'Burst_Duration_Avg_s',\n",
    "    'Burst Duration - Std (s)':'Burst_Duration_Std_s',\n",
    "    'Number of Spikes per Burst - Avg':'Spikes_per_Burst_Avg',\n",
    "    'Number of Spikes per Burst - Std':'Spikes_per_Burst_Std',\n",
    "    'Mean ISI within Burst - Avg':'Mean_ISI_within_Burst_Avg',\n",
    "    'Mean ISI within Burst - Std':'Mean_ISI_within_Burst_Std',\n",
    "    'Median ISI within Burst - Avg':'Median_ISI_within_Burst_Avg',\n",
    "    'Median ISI within Burst - Std':'Median_ISI_within_Burst_Std',\n",
    "    'Inter-Burst Interval - Avg (s)':'Inter_Burst_Interval_Avg_s',\n",
    "    'Inter-Burst Interval - Std (s)':'Inter_Burst_Interval_Std_s',\n",
    "    'Burst Frequency - Avg (Hz)':'Burst_Frequency_Avg_Hz',\n",
    "    'Burst Frequency - Std (Hz)':'Burst_Frequency_Std_Hz',\n",
    "    'Normalized Duration IQR - Avg':'Normalized_Duration_IQR_Avg',\n",
    "    'Normalized Duration IQR - Std':'Normalized_Duration_IQR_Std',\n",
    "    'IBI Coefficient of Variation - Avg':'IBI_Coeff_of_Variation_Avg',\n",
    "    'IBI Coefficient of Variation - Std':'IBI_Coeff_of_Variation_Std',\n",
    "    'Burst Percentage - Avg':'Burst_Percentage_Avg',\n",
    "    'Burst Percentage - Std':'Burst_Percentage_Std',\n",
    "    'Number of Network Bursts':'Number_of_Network_Bursts',\n",
    "    'Network Burst Frequency (Hz)':'Network_Burst_Frequency_Hz',\n",
    "    'Network Burst Duration - Avg (sec)':'Network_Burst_Duration_Avg_s',\n",
    "    'Network Burst Duration - Std (sec)':'Network_Burst_Duration_Std_s',\n",
    "    'Number of Spikes per Network Burst - Avg':'Spikes_per_Netw_Burst_Avg',\n",
    "    'Number of Spikes per Network Burst - Std':'Spikes_per_Netw_Burst_Std',\n",
    "    'Number of Elecs Participating in Burst - Avg':'Elecs_Particip_in_Brst_Avg',\n",
    "    'Number of Elecs Participating in Burst - Std':'Elecs_Particip_in_Brst_Std',\n",
    "    'Number of Spikes per Network Burst per Channel - Avg':'Spikes_Net_Brst_Channel_Avg',\n",
    "    'Number of Spikes per Network Burst per Channel - Std':'Spikes_Net_Brst_Channel_Std',\n",
    "    'Network Burst Percentage':'Network_Burst_Percentage',\n",
    "    'Network IBI Coefficient of Variation':'Network_IBI_Coeff_Variation',\n",
    "    'Network ISI Coefficient of Variation':'Network_ISI_Coeff_Variation',\n",
    "    'Network Normalized Duration IQR':'Network_Norm_Duration_IQR',\n",
    "    'Area Under Normalized Cross-Correlation':'Area_Under_Norm_Cross_Corr',\n",
    "    'Area Under Cross-Correlation':'Area_Under_Cross_Correlation',\n",
    "    'Width at Half Height of Normalized Cross-Correlation':'Width_Hf_Height_N_Cross_Corr',\n",
    "    'Width at Half Height of Cross-Correlation':'Width_Hf_Height_Cross_Corr',\n",
    "    'Synchrony Index':'Synchrony_Index'\n",
    "    }\n",
    "\n",
    "# Check all names are <=31 chars long\n",
    "for i in metrics_per_well.values():\n",
    "    if len(i) > 31:\n",
    "        print(f'\\n{i} in \"metrics_per_well\" is {len(i)} characters long, {len(i) - 31} characters over the excel worksheet name limit')\n",
    "print(f'\\n{len(metrics_per_well)} well metrics will be extracted from the advanced metrics.csv files')\n",
    "\n",
    "# Initialize a dictionary containing the original and excel-friendly names of all the per-electrode metrics desired\n",
    "metrics_per_electrode = {\n",
    "    'Number of Spikes':'Number_of_Spikes',\n",
    "    'Mean Firing Rate (Hz)':'Mean_Firing_Rate_Hz',\n",
    "    'ISI Coefficient of Variation':'ISI_Coefficient_of_Variation',\n",
    "    'Number of Bursts':'Number_of_Bursts',\n",
    "    'Burst Duration - Avg (s)':'Burst_Duration_Avg_s',\n",
    "    'Burst Duration - Std (s)':'Burst_Duration_Std_s',\n",
    "    'Number of Spikes per Burst - Avg':'Spikes_per_Burst_Avg',\n",
    "    'Number of Spikes per Burst - Std':'Spikes_per_Burst_Std',\n",
    "    'Mean ISI within Burst - Avg':'Mean_ISI_within_Burst_Avg',\n",
    "    'Mean ISI within Burst - Std':'Mean_ISI_within_Burst_Std',\n",
    "    'Median ISI within Burst - Avg':'Median_ISI_within_Burst_Avg',\n",
    "    'Median ISI within Burst - Std':'Median_ISI_within_Burst_Std',\n",
    "    'Inter-Burst Interval - Avg (s)':'Inter_Burst_Interval_Avg_s',\n",
    "    'Inter-Burst Interval - Std (s)':'Inter_Burst_Interval_Std_s',\n",
    "    'Burst Frequency (Hz)':'Burst_Frequency_Hz',\n",
    "    'IBI Coefficient of Variation':'IBI_Coefficient_of_Variation',\n",
    "    'Normalized Duration IQR':'Normalized Duration IQR',\n",
    "    'Burst Percentage':'Burst_Percentage',\n",
    "}\n",
    "\n",
    "# Check all names are <=31 chars long\n",
    "for i in metrics_per_electrode.values():\n",
    "    if len(i) > 31:\n",
    "        print(f'\\n{i} in \"metrics_per_electrode\" is {len(i)} characters long, {len(i) - 31} characters over the excel worksheet name limit')\n",
    "print(f'\\n{len(metrics_per_electrode)} electrode metrics will be extracted from the advanced metrics.csv files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af59a5-4f89-4363-a9aa-32d4009600fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before starting with the DataFrames, set display options to print all rows and columns in the notebook\n",
    "pd.set_option('display.min_rows', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', True)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d4352-e0fd-4c6b-9ef6-255143bb5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data from the selected input advanced_metrics files as pandas dataframes\n",
    "well_and_electrode_info = {}\n",
    "filtered_dict_advanced_metrics_files_treatment = {}\n",
    "filtered_dict_advanced_metrics_files_well = {}\n",
    "filtered_dict_advanced_metrics_files_electrode = {}\n",
    "advanced_metrics_files = [fl for fl in input_files if '_spike_list' not in fl]\n",
    "spike_files = [fl for fl in input_files if '_spike_list' in fl]\n",
    "\n",
    "for fl in tqdm_notebook(advanced_metrics_files,\n",
    "                        desc = f'Retrieving advanced metrics.csv data on {str(time.ctime(time.time()))}'):\n",
    "        temp = pd.read_csv(fl,\n",
    "                           header=None,sep='\\t',\n",
    "                           skip_blank_lines=False,\n",
    "                           engine='python')[0].str.strip().str.split(',', expand=True).set_index([0])\n",
    "        well_and_electrode_info[fl] =  temp[temp.index.isin(info_per_day.keys())] # Add to the dictionary only those rows from the csv file\n",
    "                                                                                                # whose index name is among the info_per_day dict keys\n",
    "        \n",
    "        filtered_dict_advanced_metrics_files_treatment[fl] = temp.loc['Treatment Averages':'Area Under Cross-Correlation - Std']\\\n",
    "                    [temp.loc['Treatment Averages':'Area Under Cross-Correlation - Std'].index.isin(metrics_per_treatment.keys())]\\\n",
    "                    .replace('', '0', inplace=False).dropna(how='all', axis=1)  # Add indexed rows from the \"fl\" csv file\n",
    "            \n",
    "        filtered_dict_advanced_metrics_files_well[fl] = temp.loc['Well Averages':'Synchrony Index']\\\n",
    "                    [temp.loc['Well Averages':'Synchrony Index'].index.isin(metrics_per_well.keys())]\\\n",
    "                    .replace('', '0', inplace=False).dropna(how='all', axis=1) # Add indexed rows from the \"fl\" csv file\n",
    "        \n",
    "        filtered_dict_advanced_metrics_files_electrode[fl] = temp.loc['Measurement':]\\\n",
    "                    [temp.loc['Measurement':].index.isin(metrics_per_electrode.keys())]\\\n",
    "                    .replace('', '0', inplace=False).dropna(how='all', axis=1) # Add indexed rows from the \"fl\" csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a96ec8-348a-456a-a765-cf0a7aeea9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data from the selected input _spike_ files as pandas dataframes\n",
    "dict_spike_files = {}\n",
    "for fl in tqdm_notebook(spike_files,\n",
    "                        desc = f'Retrieving spike_file.csv data on {str(time.ctime(time.time()))}'):\n",
    "    dict_spike_files[fl] = pd.read_csv(fl,\n",
    "               header=None,sep='\\t',\n",
    "               skip_blank_lines=False,\n",
    "               engine='python')[0].str.split(',', expand=True) # .fillna(0)\n",
    "    dict_spike_files[fl].columns = dict_spike_files[fl].iloc[0]\n",
    "    dict_spike_files[fl] = dict_spike_files[fl].iloc[1:].reset_index(drop=True).rename(columns={'Investigator': 'Information (keys)','':'Information (values)'}).set_index(['Information (keys)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cff852-df07-4f5d-b594-dab01e5763aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one example of the just-created well_and_electrode_info pandas dataframes with Mito\n",
    "well_and_electrode_info[advanced_metrics_files[0]]\n",
    "\n",
    "# Read one example of the just-created filtered_advanced_metrics_treatment pandas dataframes with Mito\n",
    "filtered_dict_advanced_metrics_files_treatment[advanced_metrics_files[0]]\n",
    "\n",
    "# Read one example of the just-created filtered_advanced_metrics_well pandas dataframes with Mito\n",
    "filtered_dict_advanced_metrics_files_well[advanced_metrics_files[0]]\n",
    "\n",
    "# Read one example of the just-created filtered_advanced_metrics_electrode pandas dataframes with Mito\n",
    "filtered_dict_advanced_metrics_files_electrode[advanced_metrics_files[0]]\n",
    "\n",
    "# Read one example of the just-created spike_files pandas dataframes with Mito\n",
    "dict_spike_files[spike_files[0]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4fe41-b57c-495c-85a7-54ecc5739cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data dictionaries by the value of their \"Original file Time\" row in the well_and_electrode_info dict\n",
    "well_and_electrode_info = dict(sorted(well_and_electrode_info.items(), key=lambda x: datetime.strptime(x[1].loc['Original File Time'][1], '%m/%d/%Y %H:%M:%S')))\n",
    "filtered_dict_advanced_metrics_files_treatment = dict([(time_point, filtered_dict_advanced_metrics_files_treatment[time_point]) for time_point in well_and_electrode_info.keys()])\n",
    "filtered_dict_advanced_metrics_files_well = dict([(time_point, filtered_dict_advanced_metrics_files_well[time_point]) for time_point in well_and_electrode_info.keys()])\n",
    "filtered_dict_advanced_metrics_files_electrode = dict([(time_point, filtered_dict_advanced_metrics_files_electrode[time_point]) for time_point in well_and_electrode_info.keys()])\n",
    "dict_spike_files = dict([(f\"{time_point.split('.csv')[0]}{'_spike_list.csv'}\", dict_spike_files[f\"{time_point.split('.csv')[0]}{'_spike_list.csv'}\"]) for time_point in well_and_electrode_info.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce0492-7187-409c-8b5a-a04a1b3ba0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spike amplitude dataframes per treatment, per well and per electrode in same structure as advanced metrics\n",
    "spikes_per_day_tables = {'Treatment':{},'Well':{},'Electrode':{}}\n",
    "baseline_day = [day for day in dict_spike_files.keys() if 'bl' in day][0]\n",
    "baseline_amps = dict_spike_files[baseline_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f4146-e75c-41c9-9df4-b4218255686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per treatment\n",
    "\n",
    "headers_treat = [\n",
    "# Headers are: treatment and coloring, in that order\n",
    "list(well_and_electrode_info[spike_files[-1].replace('_spike_list','')].loc['Treatment Averages'].dropna()),\n",
    "[{t: c for t, c in zip(well_and_electrode_info[spike_files[-1].replace('_spike_list','')].loc['Treatment'].dropna(),well_and_electrode_info[spike_files[-1].replace('_spike_list','')].loc['Well Coloring'].dropna())}[x]\n",
    " for x in list(well_and_electrode_info[spike_files[-1].replace('_spike_list','')].loc['Treatment Averages'].dropna())],\n",
    "]\n",
    "tuples_treat = list(zip(*headers_treat))\n",
    "index_treat = pd.MultiIndex.from_tuples(tuples_treat, names=['Treatment Averages', 'Coloring'])\n",
    "\n",
    "spikes_per_day_tables['Treatment']['Amplitude (uV)'] = pd.DataFrame(index=dict_spike_files.keys(),\n",
    "                            columns=index_treat)\n",
    "spikes_per_day_tables['Treatment']['nAmplitude (uV)'] = pd.DataFrame(index=dict_spike_files.keys(),\n",
    "                            columns=index_treat)\n",
    "for day, ampdata in tqdm_notebook(dict_spike_files.items(),\n",
    "                                 desc = f'Filling amplitude dataframes on {str(time.ctime(time.time()))}'):\n",
    "    wells_treat = {t:[] for w,t in zip(ampdata.loc['Well'],ampdata.loc['Treatment']) if t == t}\n",
    "    for w,t in zip(ampdata.loc['Well'],ampdata.loc['Treatment']):\n",
    "        wells_treat[t].append(w)\n",
    "    for treatment in tqdm_notebook(headers_treat[0],\n",
    "                                  desc = f'Filling amplitude dataframes for {day} on {str(time.ctime(time.time()))}'):\n",
    "        spikes_per_day_tables['Treatment']['Amplitude (uV)'].loc[day,treatment] = ampdata[:-9].query('Electrode.str.slice(0,2) in @wells_treat[@treatment]',inplace=False)['Amplitude (mV)'].astype(float).mean()*1000\n",
    "        with pd.option_context('mode.use_inf_as_na', True): # this option prevents black color displaying for infinite values by background_gradient    \n",
    "            spikes_per_day_tables['Treatment']['nAmplitude (uV)'].loc[day,treatment] = (ampdata[:-9].query('Electrode.str.slice(0,2) in @wells_treat[@treatment]',inplace=False)['Amplitude (mV)'].astype(float).mean()*1000)/(baseline_amps[:-9].query('Electrode.str.slice(0,2) in @wells_treat[@treatment]')['Amplitude (mV)'].astype(float).mean()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ce905-af73-4245-a92d-0b5cc6ceb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per well\n",
    "\n",
    "headers_well = [\n",
    "# Headers are: well,treatment and coloring, in that order\n",
    "list(dict_spike_files[spike_files[-1]].loc['Well'].dropna()),\n",
    "list(dict_spike_files[spike_files[-1]].loc['Treatment'].dropna()),\n",
    "list(dict_spike_files[spike_files[-1]].loc['Well Coloring'].dropna())\n",
    "]\n",
    "tuples_well = list(zip(*headers_well))\n",
    "index_well = pd.MultiIndex.from_tuples(tuples_well, names=['Well', 'Treatment', 'Coloring'])\n",
    "\n",
    "spikes_per_day_tables['Well']['Amplitude (uV)'] = pd.DataFrame(index=dict_spike_files.keys(),\n",
    "                            columns=index_well)\n",
    "spikes_per_day_tables['Well']['nAmplitude (uV)'] = pd.DataFrame(index=dict_spike_files.keys(),\n",
    "                            columns=index_well)\n",
    "for day, ampdata in tqdm_notebook(dict_spike_files.items(),\n",
    "                                 desc = f'Filling amplitude dataframes on {str(time.ctime(time.time()))}'):\n",
    "    for well in tqdm_notebook(headers_well[0],\n",
    "                                  desc = f'Filling amplitude dataframes for {day} on {str(time.ctime(time.time()))}'):\n",
    "        spikes_per_day_tables['Well']['Amplitude (uV)'].loc[day,well] = ampdata[:-9].query('Electrode.str.slice(0,2) == @well',inplace=False)['Amplitude (mV)'].astype(float).mean()*1000\n",
    "        with pd.option_context('mode.use_inf_as_na', True): # this option prevents black color displaying for infinite values by background_gradient    \n",
    "            spikes_per_day_tables['Well']['nAmplitude (uV)'].loc[day,well] = (ampdata[:-9].query('Electrode.str.slice(0,2) == @well',inplace=False)['Amplitude (mV)'].astype(float).mean()*1000)/(baseline_amps[:-9].query('Electrode.str.slice(0,2) == @well')['Amplitude (mV)'].astype(float).mean()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797fc66d-4434-40a2-ad67-8ea41a1e44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per electrode\n",
    "# Alternative is to only run this cell and produce the per-well and per-treatment using parallelized pd.groupby()\n",
    "headers_elec = [\n",
    "# Headers are: electrode (measurement), treatment and coloring, in that order\n",
    "list(well_and_electrode_info[spike_files[-1].replace('_spike_list','')].loc['Measurement'].dropna()),\n",
    "list(w for t, w in zip(dict_spike_files[spike_files[-1]].loc['Treatment'],\n",
    "dict_spike_files[spike_files[-1]].loc['Well']) for e in\n",
    "well_and_electrode_info[spike_files[-1].replace('_spike_list','')].loc['Measurement'].dropna() if e[:2] == w),\n",
    "list(t for t, w in zip(dict_spike_files[spike_files[-1]].loc['Treatment'],\n",
    "dict_spike_files[spike_files[-1]].loc['Well']) for e in\n",
    "well_and_electrode_info[spike_files[-1].replace('_spike_list','')].loc['Measurement'].dropna() if e[:2] == w),\n",
    "list(c for c, w in zip(dict_spike_files[spike_files[-1]].loc['Well Coloring'],\n",
    "dict_spike_files[spike_files[-1]].loc['Well']) for e in\n",
    "well_and_electrode_info[spike_files[-1].replace('_spike_list','')].loc['Measurement'].dropna() if e[:2] == w)\n",
    "]\n",
    "tuples_elec = list(zip(*headers_elec))\n",
    "index_elec = pd.MultiIndex.from_tuples(tuples_elec, names=['Electrode', 'Well', 'Treatment', 'Coloring'])\n",
    "\n",
    "spikes_per_day_tables['Electrode']['Amplitude (uV)'] = pd.DataFrame(index=dict_spike_files.keys(),\n",
    "                            columns=index_elec)\n",
    "spikes_per_day_tables['Electrode']['nAmplitude (uV)'] = pd.DataFrame(index=dict_spike_files.keys(),\n",
    "                            columns=index_elec)\n",
    "for day, ampdata in tqdm_notebook(dict_spike_files.items(),\n",
    "                                 desc = f'Filling amplitude dataframes on {str(time.ctime(time.time()))}'):\n",
    "    for electrode in tqdm_notebook(headers_elec[0],\n",
    "                                  desc = f'Filling amplitude dataframes for {day} on {str(time.ctime(time.time()))}'):\n",
    "        spikes_per_day_tables['Electrode']['Amplitude (uV)'].loc[day,electrode] = ampdata.query('Electrode == @electrode',inplace=False)['Amplitude (mV)'].astype(float).mean()*1000\n",
    "        with pd.option_context('mode.use_inf_as_na', True): # this option prevents black color displaying for infinite values by background_gradient    \n",
    "            spikes_per_day_tables['Electrode']['nAmplitude (uV)'].loc[day,electrode] = (ampdata.query('Electrode == @electrode',inplace=False)['Amplitude (mV)'].astype(float).mean()*1000)/(baseline_amps.query('Electrode == @electrode')['Amplitude (mV)'].astype(float).mean()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a8eec-198e-443e-ac3b-eb9a0b650322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of DataFrames, each containing the data for each metric, organized by day (rows) and TREATMENT (columns)\n",
    "\n",
    "metrics_per_day_and_treatment_tables = {}\n",
    "metrics_per_day_and_treatment_tables['Amplitude (uV)'] = spikes_per_day_tables['Treatment']['Amplitude (uV)'].fillna(0)\n",
    "metrics_per_day_and_treatment_tables['nAmplitude (uV)'] = spikes_per_day_tables['Treatment']['nAmplitude (uV)'].fillna(0)\n",
    "baseline_day = [day for day in filtered_dict_advanced_metrics_files_treatment.keys() if 'bl' in day][0]\n",
    "baseline_df = filtered_dict_advanced_metrics_files_treatment[baseline_day]\n",
    "\n",
    "for day, dataframe in tqdm_notebook(filtered_dict_advanced_metrics_files_treatment.items(),\n",
    "                                    desc = f'Initializing per-treatment dictionaries on {str(time.ctime(time.time()))}'):\n",
    "    for k, v in metrics_per_treatment.items():\n",
    "        headers_treatment = [\n",
    "        # Headers are: treatment and coloring, in that order\n",
    "        list(well_and_electrode_info[day].loc['Treatment Averages'].dropna()),\n",
    "        [{t: c for t, c in zip(well_and_electrode_info[day].loc['Treatment'].dropna(),well_and_electrode_info[day].loc['Well Coloring'].dropna())}[x]\n",
    "         for x in list(well_and_electrode_info[day].loc['Treatment Averages'].dropna())],\n",
    "        ]\n",
    "        tuples_treat = list(zip(*headers_treatment))\n",
    "        index_treat = pd.MultiIndex.from_tuples(tuples_treat, names=['Treatment Averages', 'Coloring'])\n",
    "        metrics_per_day_and_treatment_tables[v] = pd.DataFrame(index=filtered_dict_advanced_metrics_files_treatment.keys(),\n",
    "                                columns=index_treat)\n",
    "        metrics_per_day_and_treatment_tables[f'n{v}'] = pd.DataFrame(index=filtered_dict_advanced_metrics_files_treatment.keys(),\n",
    "                                columns=index_treat)\n",
    "\n",
    "for day, dataframe in tqdm_notebook(filtered_dict_advanced_metrics_files_treatment.items(),\n",
    "                                    desc = f'Filling per-treatment dictionaries on {str(time.ctime(time.time()))}'):\n",
    "    for k, v in metrics_per_treatment.items():\n",
    "        metrics_per_day_and_treatment_tables[v].loc[day] = list(dataframe.loc[k])\n",
    "        with pd.option_context('mode.use_inf_as_na', True): # this option prevents black color displaying for infinite values by background_gradient \n",
    "            metrics_per_day_and_treatment_tables[f'n{v}'].loc[day] = list((dataframe.loc[k].astype(float)/baseline_df.loc[k].astype(float)).fillna(0))\n",
    "        \n",
    "with pd.ExcelWriter('Adv_metrics_treatment.xlsx', engine='xlsxwriter',\n",
    "                    engine_kwargs={'options': {'strings_to_numbers': True}}) as writer:\n",
    "    for df_name, df in tqdm_notebook(metrics_per_day_and_treatment_tables.items(),\n",
    "                                    desc = f'Writing per-treatment dictionaries to excel on {str(time.ctime(time.time()))}'):\n",
    "        styler = df.sort_values(by=['Treatment Averages'],axis=1).style \n",
    "        for color in set(index_treat.get_level_values('Coloring')):\n",
    "            styler.background_gradient(cmap=sns.light_palette(color, as_cmap=True),\n",
    "                                       axis=None,low=0.5,high=0.7,\n",
    "                                       subset=[w for w, c in zip(list(index_treat.get_level_values('Treatment Averages')),\n",
    "                                                                 list(index_treat.get_level_values('Coloring'))) if c==color])\n",
    "        styler.to_excel(writer, sheet_name=df_name)\n",
    "        for column in df:\n",
    "            column_width = max(df.index.astype(str).map(len).max(), len(column))\n",
    "            col_idx = df.columns.get_loc(column)\n",
    "            writer.sheets[df_name].set_column(col_idx, col_idx, column_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925e5b5-4876-4215-b4d8-a7458263ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of DataFrames containing the data for each metric organized by day (rows) and WELL (columns)\n",
    "\n",
    "metrics_per_day_and_well_tables = {}\n",
    "metrics_per_day_and_well_tables['Amplitude (uV)'] = spikes_per_day_tables['Well']['Amplitude (uV)'].fillna(0)\n",
    "metrics_per_day_and_well_tables['nAmplitude (uV)'] = spikes_per_day_tables['Well']['nAmplitude (uV)'].fillna(0)\n",
    "baseline_day = [day for day in filtered_dict_advanced_metrics_files_well.keys() if 'bl' in day][0]\n",
    "baseline_df = filtered_dict_advanced_metrics_files_well[baseline_day]\n",
    "\n",
    "for day, dataframe in tqdm_notebook(filtered_dict_advanced_metrics_files_well.items(),\n",
    "                                    desc = f'Initializing per-well dictionaries on {str(time.ctime(time.time()))}'):\n",
    "    for k, v in metrics_per_well.items():\n",
    "        headers_well = [\n",
    "        # Headers are: well,treatment and coloring, in that order\n",
    "        list(well_and_electrode_info[day].loc['Well'].dropna()),\n",
    "        list(well_and_electrode_info[day].loc['Treatment'].dropna()),\n",
    "        list(well_and_electrode_info[day].loc['Well Coloring'].dropna())\n",
    "        ]\n",
    "        tuples_well = list(zip(*headers_well))\n",
    "        index_well = pd.MultiIndex.from_tuples(tuples_well, names=['Well', 'Treatment', 'Coloring'])\n",
    "        metrics_per_day_and_well_tables[v] = pd.DataFrame(index=filtered_dict_advanced_metrics_files_well.keys(),\n",
    "                                columns=index_well)\n",
    "        metrics_per_day_and_well_tables[f'n{v}'] = pd.DataFrame(index=filtered_dict_advanced_metrics_files_well.keys(),\n",
    "                                columns=index_well)\n",
    "\n",
    "for day, dataframe in tqdm_notebook(filtered_dict_advanced_metrics_files_well.items(),\n",
    "                                    desc = f'Filling per-well dictionaries on {str(time.ctime(time.time()))}'):\n",
    "    for k, v in metrics_per_well.items():\n",
    "        metrics_per_day_and_well_tables[v].loc[day] = list(dataframe.loc[k])\n",
    "        with pd.option_context('mode.use_inf_as_na', True):\n",
    "            metrics_per_day_and_well_tables[f'n{v}'].loc[day] = list((dataframe.loc[k].astype(float)/baseline_df.loc[k].astype(float)).fillna(0))\n",
    "\n",
    "with pd.ExcelWriter('Adv_metrics_well.xlsx', engine='xlsxwriter',\n",
    "                    engine_kwargs={'options': {'strings_to_numbers': True}}) as writer:\n",
    "    for df_name, df in tqdm_notebook(metrics_per_day_and_well_tables.items(),\n",
    "                                    desc = f'Writing per-well dictionaries to excel on {str(time.ctime(time.time()))}'):\n",
    "        styler = df.sort_values(by=['Treatment'],axis=1).style \n",
    "        for color in set(index_well.get_level_values('Coloring')):\n",
    "            styler.background_gradient(cmap=sns.light_palette(color, as_cmap=True),\n",
    "                                       axis=None,low=0.5,high=0.7,\n",
    "                                       subset=[w for w, c in zip(list(index_well.get_level_values('Well')), list(index_well.get_level_values('Coloring'))) if c==color])\n",
    "        styler.to_excel(writer, sheet_name=df_name)\n",
    "        for column in df:\n",
    "            column_width = max(df.index.astype(str).map(len).max(), len(column))\n",
    "            col_idx = df.columns.get_loc(column)\n",
    "            writer.sheets[df_name].set_column(col_idx, col_idx, column_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e34538-2554-4443-92fe-72575a312b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of DataFrames containing the data for each metric organized by day (rows) and ELECTRODE (columns)\n",
    "\n",
    "metrics_per_day_and_electrode_tables = {}\n",
    "metrics_per_day_and_electrode_tables['Amplitude (uV)'] = spikes_per_day_tables['Electrode']['Amplitude (uV)'].fillna(0)\n",
    "metrics_per_day_and_electrode_tables['nAmplitude (uV)'] = spikes_per_day_tables['Electrode']['nAmplitude (uV)'].fillna(0)\n",
    "baseline_day = [day for day in filtered_dict_advanced_metrics_files_electrode.keys() if 'bl' in day][0]\n",
    "baseline_df = filtered_dict_advanced_metrics_files_electrode[baseline_day]\n",
    "\n",
    "for day, dataframe in tqdm_notebook(filtered_dict_advanced_metrics_files_electrode.items(),\n",
    "                                    desc = f'Initializing per-electrode dictionaries on {str(time.ctime(time.time()))}'):\n",
    "    for k, v in metrics_per_electrode.items():\n",
    "        headers_elec = [\n",
    "        # Headers are: electrode, treatment and coloring, in that order\n",
    "        list(well_and_electrode_info[day].loc['Measurement'].dropna()),\n",
    "        list(t for t, w in zip(well_and_electrode_info[day].loc['Treatment'].dropna(),\n",
    "        well_and_electrode_info[day].loc['Well'].dropna()) for e in\n",
    "        well_and_electrode_info[day].loc['Measurement'].dropna() if e[:2] == w),\n",
    "        list(c for c, w in zip(well_and_electrode_info[day].loc['Well Coloring'].dropna(),\n",
    "        well_and_electrode_info[day].loc['Well'].dropna()) for e in\n",
    "        well_and_electrode_info[day].loc['Measurement'].dropna() if e[:2] == w)\n",
    "        ]\n",
    "        tuples_elec = list(zip(*headers_elec))\n",
    "        index_elec = pd.MultiIndex.from_tuples(tuples_elec, names=['Electrode', 'Treatment', 'Coloring'])\n",
    "        metrics_per_day_and_electrode_tables[v] = pd.DataFrame(index=filtered_dict_advanced_metrics_files_electrode.keys(),\n",
    "                                columns=index_elec)\n",
    "        metrics_per_day_and_electrode_tables[f'n{v}'] = pd.DataFrame(index=filtered_dict_advanced_metrics_files_electrode.keys(),\n",
    "                                columns=index_elec)\n",
    "\n",
    "for day, dataframe in tqdm_notebook(filtered_dict_advanced_metrics_files_electrode.items(),\n",
    "                                    desc = f'Filling per-electrode dictionaries on {str(time.ctime(time.time()))}'):\n",
    "    for k, v in metrics_per_electrode.items():\n",
    "        metrics_per_day_and_electrode_tables[v].loc[day] = list(dataframe.loc[k])\n",
    "        with pd.option_context('mode.use_inf_as_na', True):\n",
    "            metrics_per_day_and_electrode_tables[f'n{v}'].loc[day] = list((dataframe.loc[k].astype(float)/baseline_df.loc[k].astype(float)).fillna(0))\n",
    "\n",
    "with pd.ExcelWriter('Adv_metrics_electrode.xlsx', engine='xlsxwriter',\n",
    "                    engine_kwargs={'options': {'strings_to_numbers': True}}) as writer:\n",
    "    for df_name, df in tqdm_notebook(metrics_per_day_and_electrode_tables.items(),\n",
    "                                    desc = f'Writing per-electrode dictionaries to excel on {str(time.ctime(time.time()))}'):\n",
    "        styler = df.sort_values(by=['Treatment'],axis=1).style \n",
    "        for color in set(index_elec.get_level_values('Coloring')):\n",
    "            styler.background_gradient(cmap=sns.light_palette(color, as_cmap=True),\n",
    "                                       axis=None,low=0.5,high=0.7,\n",
    "                                       subset=[e for e, c in zip(list(index_elec.get_level_values('Electrode')), list(index_elec.get_level_values('Coloring'))) if c==color])\n",
    "        styler.to_excel(writer, sheet_name=df_name)\n",
    "        for column in df:\n",
    "            column_width = max(df.index.astype(str).map(len).max(), len(column))\n",
    "            col_idx = df.columns.get_loc(column)\n",
    "            writer.sheets[df_name].set_column(col_idx, col_idx, column_width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
